{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Scraping r/WallStreetBets...\n",
      "INFO:__main__:Found 214 mentions in r/WallStreetBets\n",
      "INFO:__main__:Scraping r/StockMarket...\n",
      "INFO:__main__:Found 215 mentions in r/StockMarket\n",
      "INFO:__main__:Scraping r/investing...\n",
      "INFO:__main__:Found 304 mentions in r/investing\n",
      "INFO:__main__:Scraping r/dividends...\n",
      "INFO:__main__:Found 174 mentions in r/dividends\n",
      "INFO:__main__:Scraping r/cryptocurrency...\n",
      "INFO:__main__:Found 154 mentions in r/cryptocurrency\n",
      "INFO:__main__:Scraping r/Investing_Discussion...\n",
      "INFO:__main__:Found 184 mentions in r/Investing_Discussion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mentions found: 1245\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import List, Dict, Set\n",
    "from dataclasses import dataclass\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class StockMention:\n",
    "    date: datetime.date\n",
    "    time: datetime.time\n",
    "    subreddit: str\n",
    "    title: str\n",
    "    text: str\n",
    "    ticker: str\n",
    "    company_name: str\n",
    "\n",
    "class RedditStockScraper:\n",
    "    def __init__(self, client_id: str, client_secret: str, user_agent: str):\n",
    "        \"\"\"Initialize the Reddit scraper with API credentials.\"\"\"\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            user_agent=user_agent\n",
    "        )\n",
    "        \n",
    "        self.stocks = {\n",
    "            'NVDA': 'NVIDIA',\n",
    "            'TSLA': 'Tesla',\n",
    "            'AAPL': 'Apple',\n",
    "            'MC.PA': 'LVMH'\n",
    "        }\n",
    "        \n",
    "        self.subreddits = [\n",
    "            \"WallStreetBets\",\n",
    "            \"StockMarket\",\n",
    "            \"investing\",\n",
    "            \"dividends\",\n",
    "            \"cryptocurrency\",\n",
    "            \"Investing_Discussion\"\n",
    "        ]\n",
    "\n",
    "    def _validate_dates(self, start_date: str, end_date: str) -> tuple:\n",
    "        \"\"\"Validate and convert date strings to timestamps.\"\"\"\n",
    "        try:\n",
    "            start_timestamp = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp())\n",
    "            end_timestamp = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp())\n",
    "            if start_timestamp > end_timestamp:\n",
    "                raise ValueError(\"Start date must be before end date\")\n",
    "            return start_timestamp, end_timestamp\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"Date validation error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _extract_stock_mentions(self, text: str) -> Set[str]:\n",
    "        \"\"\"Extract stock mentions from text using multiple patterns.\"\"\"\n",
    "        if not text:\n",
    "            return set()\n",
    "\n",
    "        mentions = set()\n",
    "        \n",
    "        # Find $TICKER mentions\n",
    "        dollar_mentions = set(re.findall(r'\\$([A-Z]{1,5})', text))\n",
    "        \n",
    "        # Find company name mentions\n",
    "        company_mentions = {ticker for ticker, company in self.stocks.items() \n",
    "                          if company.lower() in text.lower()}\n",
    "        \n",
    "        # Find raw ticker mentions\n",
    "        ticker_mentions = {ticker for ticker in self.stocks.keys() \n",
    "                         if ticker in text.upper()}\n",
    "        \n",
    "        mentions.update(dollar_mentions, company_mentions, ticker_mentions)\n",
    "        return {m for m in mentions if m in self.stocks}\n",
    "\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=60, period=60)  # Reddit API rate limit\n",
    "    def _fetch_subreddit_posts(self, subreddit_name: str, start_timestamp: int, \n",
    "                             end_timestamp: int) -> List[StockMention]:\n",
    "        \"\"\"Fetch posts from a subreddit within the specified timeframe.\"\"\"\n",
    "        mentions = []\n",
    "        subreddit = self.reddit.subreddit(subreddit_name)\n",
    "        \n",
    "        search_query = ' OR '.join(f'({ticker} OR \"{company}\")' \n",
    "                                 for ticker, company in self.stocks.items())\n",
    "        \n",
    "        try:\n",
    "            for submission in subreddit.search(search_query,\n",
    "                                             syntax='lucene',\n",
    "                                             time_filter='all',\n",
    "                                             sort='new',\n",
    "                                             limit=None):\n",
    "                \n",
    "                if submission.created_utc < start_timestamp:\n",
    "                    break\n",
    "                    \n",
    "                if submission.created_utc <= end_timestamp:\n",
    "                    text = f\"{submission.title} {submission.selftext}\"\n",
    "                    stock_mentions = self._extract_stock_mentions(text)\n",
    "                    \n",
    "                    timestamp = datetime.fromtimestamp(submission.created_utc)\n",
    "                    \n",
    "                    for ticker in stock_mentions:\n",
    "                        mentions.append(StockMention(\n",
    "                            date=timestamp.date(),\n",
    "                            time=timestamp.time(),\n",
    "                            subreddit=subreddit_name,\n",
    "                            title=submission.title,\n",
    "                            text=submission.selftext,\n",
    "                            ticker=ticker,\n",
    "                            company_name=self.stocks[ticker]\n",
    "                        ))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error scraping r/{subreddit_name}: {e}\")\n",
    "            raise\n",
    "            \n",
    "        return mentions\n",
    "\n",
    "    def get_posts_by_timeframe(self, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all stock mentions within the specified timeframe.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date in 'YYYY-MM-DD' format\n",
    "            end_date: End date in 'YYYY-MM-DD' format\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing all stock mentions\n",
    "        \"\"\"\n",
    "        start_timestamp, end_timestamp = self._validate_dates(start_date, end_date)\n",
    "        all_mentions = []\n",
    "        \n",
    "        for subreddit_name in self.subreddits:\n",
    "            try:\n",
    "                logger.info(f\"Scraping r/{subreddit_name}...\")\n",
    "                mentions = self._fetch_subreddit_posts(\n",
    "                    subreddit_name, start_timestamp, end_timestamp\n",
    "                )\n",
    "                all_mentions.extend(mentions)\n",
    "                logger.info(f\"Found {len(mentions)} mentions in r/{subreddit_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to scrape r/{subreddit_name}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return pd.DataFrame([vars(mention) for mention in all_mentions])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    \n",
    "    scraper = RedditStockScraper(\n",
    "        client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "        client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "        user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "    )\n",
    "    \n",
    "    df = scraper.get_posts_by_timeframe('2024-01-01', '2025-01-31')\n",
    "    print(f\"Total mentions found: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>21:53:38</td>\n",
       "      <td>WallStreetBets</td>\n",
       "      <td>Why is nvidia stock going down when deep seek ...</td>\n",
       "      <td>I understand why ai company stock going down b...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>21:52:57</td>\n",
       "      <td>WallStreetBets</td>\n",
       "      <td>Proof even sophisticated investors don't research</td>\n",
       "      <td>It hasn't even been a week and people are doom...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>21:34:57</td>\n",
       "      <td>WallStreetBets</td>\n",
       "      <td>I sold my index funds to sell Nvidia puts last...</td>\n",
       "      <td>F</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>21:29:35</td>\n",
       "      <td>WallStreetBets</td>\n",
       "      <td>These are the 3 largest drops in NVDA history,...</td>\n",
       "      <td>https://preview.redd.it/toblad0cjlfe1.png?widt...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>20:51:22</td>\n",
       "      <td>WallStreetBets</td>\n",
       "      <td>Believe it or not calls it is</td>\n",
       "      <td>NVDA just went on a firesale today and dragged...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>19:02:23</td>\n",
       "      <td>Investing_Discussion</td>\n",
       "      <td>Tesla earnings</td>\n",
       "      <td>What is everyone’s thoughts on TSLA earnings c...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>15:20:56</td>\n",
       "      <td>Investing_Discussion</td>\n",
       "      <td>Improve my portfolio strategy</td>\n",
       "      <td>started with stocks then got into ETFs.\\nI do ...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>07:06:05</td>\n",
       "      <td>Investing_Discussion</td>\n",
       "      <td>Should I invest in Individual companies if I'm...</td>\n",
       "      <td>Should I invest in individual companies like t...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>07:06:05</td>\n",
       "      <td>Investing_Discussion</td>\n",
       "      <td>Should I invest in Individual companies if I'm...</td>\n",
       "      <td>Should I invest in individual companies like t...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>01:21:51</td>\n",
       "      <td>Investing_Discussion</td>\n",
       "      <td>China’s BYD is selling more electric cars than...</td>\n",
       "      <td>[Link to the full article (2 min read)](https:...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      time             subreddit  \\\n",
       "0     2025-01-27  21:53:38        WallStreetBets   \n",
       "1     2025-01-27  21:52:57        WallStreetBets   \n",
       "2     2025-01-27  21:34:57        WallStreetBets   \n",
       "3     2025-01-27  21:29:35        WallStreetBets   \n",
       "4     2025-01-27  20:51:22        WallStreetBets   \n",
       "...          ...       ...                   ...   \n",
       "1240  2024-01-08  19:02:23  Investing_Discussion   \n",
       "1241  2024-01-07  15:20:56  Investing_Discussion   \n",
       "1242  2024-01-04  07:06:05  Investing_Discussion   \n",
       "1243  2024-01-04  07:06:05  Investing_Discussion   \n",
       "1244  2024-01-03  01:21:51  Investing_Discussion   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Why is nvidia stock going down when deep seek ...   \n",
       "1     Proof even sophisticated investors don't research   \n",
       "2     I sold my index funds to sell Nvidia puts last...   \n",
       "3     These are the 3 largest drops in NVDA history,...   \n",
       "4                         Believe it or not calls it is   \n",
       "...                                                 ...   \n",
       "1240                                     Tesla earnings   \n",
       "1241                      Improve my portfolio strategy   \n",
       "1242  Should I invest in Individual companies if I'm...   \n",
       "1243  Should I invest in Individual companies if I'm...   \n",
       "1244  China’s BYD is selling more electric cars than...   \n",
       "\n",
       "                                                   text ticker company_name  \n",
       "0     I understand why ai company stock going down b...   NVDA       NVIDIA  \n",
       "1     It hasn't even been a week and people are doom...   NVDA       NVIDIA  \n",
       "2                                                     F   NVDA       NVIDIA  \n",
       "3     https://preview.redd.it/toblad0cjlfe1.png?widt...   NVDA       NVIDIA  \n",
       "4     NVDA just went on a firesale today and dragged...   NVDA       NVIDIA  \n",
       "...                                                 ...    ...          ...  \n",
       "1240  What is everyone’s thoughts on TSLA earnings c...   TSLA        Tesla  \n",
       "1241  started with stocks then got into ETFs.\\nI do ...   AAPL        Apple  \n",
       "1242  Should I invest in individual companies like t...   TSLA        Tesla  \n",
       "1243  Should I invest in individual companies like t...   AAPL        Apple  \n",
       "1244  [Link to the full article (2 min read)](https:...   TSLA        Tesla  \n",
       "\n",
       "[1245 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../bertopic_project/data/stock_mentions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching data for NVDA...\n",
      "INFO:__main__:Successfully fetched data for NVDA\n",
      "INFO:__main__:Fetching data for TSLA...\n",
      "INFO:__main__:Successfully fetched data for TSLA\n",
      "INFO:__main__:Fetching data for AAPL...\n",
      "INFO:__main__:Successfully fetched data for AAPL\n",
      "INFO:__main__:Fetching data for MC.PA...\n",
      "INFO:__main__:Successfully fetched data for MC.PA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the data:\n",
      "Price       Date Ticker Stock Name        Open        High         Low  \\\n",
      "536   2024-01-02   AAPL      Apple  186.237618  187.521338  182.993517   \n",
      "804   2024-01-02  MC.PA       LVMH  726.230050  726.720746  705.326413   \n",
      "0     2024-01-02   NVDA     NVIDIA   49.230042   49.281026   47.581511   \n",
      "268   2024-01-02   TSLA      Tesla  250.080002  251.250000  244.410004   \n",
      "537   2024-01-03   AAPL      Apple  183.321908  184.973819  182.535751   \n",
      "\n",
      "Price       Close     Volume  \n",
      "536    184.734985   82488700  \n",
      "804    709.546387     271775  \n",
      "0       48.154346  411254000  \n",
      "268    248.419998  104654200  \n",
      "537    183.351761   58414500  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1078 entries, 536 to 535\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        1078 non-null   datetime64[ns]\n",
      " 1   Ticker      1078 non-null   object        \n",
      " 2   Stock Name  1078 non-null   object        \n",
      " 3   Open        1078 non-null   float64       \n",
      " 4   High        1078 non-null   float64       \n",
      " 5   Low         1078 non-null   float64       \n",
      " 6   Close       1078 non-null   float64       \n",
      " 7   Volume      1078 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(2)\n",
      "memory usage: 75.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class StockDataFetcher:\n",
    "    def __init__(self):\n",
    "        self.stocks = {\n",
    "            'NVDA': 'NVIDIA',\n",
    "            'TSLA': 'Tesla',\n",
    "            'AAPL': 'Apple',\n",
    "            'MC.PA': 'LVMH'\n",
    "        }\n",
    "    \n",
    "    def fetch_stock_data(self, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch stock data and return a clean DataFrame.\n",
    "        \"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        for ticker, company_name in self.stocks.items():\n",
    "            try:\n",
    "                logger.info(f\"Fetching data for {ticker}...\")\n",
    "                \n",
    "                # Fetch data for single stock\n",
    "                df = yf.download(\n",
    "                    ticker,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    progress=False\n",
    "                )\n",
    "                \n",
    "                # Clean up the DataFrame\n",
    "                df = df.reset_index()  # Make Date a column\n",
    "                df = df.droplevel(1, axis=1)  # Remove the ticker level from columns\n",
    "                \n",
    "                # Add identifier columns\n",
    "                df['Ticker'] = ticker\n",
    "                df['Stock Name'] = company_name\n",
    "                \n",
    "                all_data.append(df)\n",
    "                logger.info(f\"Successfully fetched data for {ticker}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error fetching data for {ticker}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_data:\n",
    "            raise ValueError(\"No data was fetched for any stock\")\n",
    "            \n",
    "        # Combine all stock data\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Reorder columns to desired format\n",
    "        column_order = ['Date', 'Ticker', 'Stock Name', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        combined_df = combined_df[column_order]\n",
    "        \n",
    "        # Sort by Date and Ticker\n",
    "        combined_df = combined_df.sort_values(['Date', 'Ticker'])\n",
    "        \n",
    "        return combined_df\n",
    "\n",
    "def main():\n",
    "    # Initialize fetcher\n",
    "    fetcher = StockDataFetcher()\n",
    "    \n",
    "    # Set date range\n",
    "    start_date = '2024-01-01'\n",
    "    end_date = '2024-01-31'\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        df = fetcher.fetch_stock_data(start_date, end_date)\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv('stock_data.csv', index=False)\n",
    "        \n",
    "        # Display first few rows\n",
    "        print(\"\\nFirst few rows of the data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Display basic information\n",
    "        print(\"\\nDataFrame Info:\")\n",
    "        print(df.info())\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>184.734970</td>\n",
       "      <td>187.521323</td>\n",
       "      <td>182.993502</td>\n",
       "      <td>186.237603</td>\n",
       "      <td>82488700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>183.351746</td>\n",
       "      <td>184.973804</td>\n",
       "      <td>182.535736</td>\n",
       "      <td>183.321893</td>\n",
       "      <td>58414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>181.023178</td>\n",
       "      <td>182.197418</td>\n",
       "      <td>179.998201</td>\n",
       "      <td>181.261998</td>\n",
       "      <td>71983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>180.296707</td>\n",
       "      <td>181.869006</td>\n",
       "      <td>179.291637</td>\n",
       "      <td>181.102771</td>\n",
       "      <td>62303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>184.655365</td>\n",
       "      <td>184.695178</td>\n",
       "      <td>180.615161</td>\n",
       "      <td>181.202281</td>\n",
       "      <td>59144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>184.237411</td>\n",
       "      <td>184.247357</td>\n",
       "      <td>181.839157</td>\n",
       "      <td>183.023358</td>\n",
       "      <td>42841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>185.282303</td>\n",
       "      <td>185.491271</td>\n",
       "      <td>183.023365</td>\n",
       "      <td>183.451277</td>\n",
       "      <td>46792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>184.685226</td>\n",
       "      <td>186.138115</td>\n",
       "      <td>182.724829</td>\n",
       "      <td>185.630592</td>\n",
       "      <td>49128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>185.013611</td>\n",
       "      <td>185.829621</td>\n",
       "      <td>184.287174</td>\n",
       "      <td>185.152928</td>\n",
       "      <td>40444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>182.734772</td>\n",
       "      <td>183.361690</td>\n",
       "      <td>180.047923</td>\n",
       "      <td>181.271937</td>\n",
       "      <td>65603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>181.789383</td>\n",
       "      <td>182.038164</td>\n",
       "      <td>179.420996</td>\n",
       "      <td>180.386269</td>\n",
       "      <td>47317400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>187.710419</td>\n",
       "      <td>188.217927</td>\n",
       "      <td>184.924066</td>\n",
       "      <td>185.182793</td>\n",
       "      <td>78005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>190.626114</td>\n",
       "      <td>191.014212</td>\n",
       "      <td>187.899482</td>\n",
       "      <td>188.406990</td>\n",
       "      <td>68741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>192.944748</td>\n",
       "      <td>194.377730</td>\n",
       "      <td>191.322690</td>\n",
       "      <td>191.362503</td>\n",
       "      <td>60133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>194.228470</td>\n",
       "      <td>194.795698</td>\n",
       "      <td>192.885060</td>\n",
       "      <td>194.069261</td>\n",
       "      <td>42355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>193.551773</td>\n",
       "      <td>195.422613</td>\n",
       "      <td>193.392549</td>\n",
       "      <td>194.467286</td>\n",
       "      <td>53631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>193.223404</td>\n",
       "      <td>195.313172</td>\n",
       "      <td>192.168574</td>\n",
       "      <td>194.268288</td>\n",
       "      <td>54822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>191.481918</td>\n",
       "      <td>193.810507</td>\n",
       "      <td>191.004263</td>\n",
       "      <td>193.322905</td>\n",
       "      <td>44594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>190.795288</td>\n",
       "      <td>191.262998</td>\n",
       "      <td>188.655776</td>\n",
       "      <td>191.073922</td>\n",
       "      <td>47145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>187.123260</td>\n",
       "      <td>190.864939</td>\n",
       "      <td>186.556047</td>\n",
       "      <td>190.009132</td>\n",
       "      <td>55859400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close        High         Low        Open    Volume\n",
       "Ticker            AAPL        AAPL        AAPL        AAPL      AAPL\n",
       "Date                                                                \n",
       "2024-01-02  184.734970  187.521323  182.993502  186.237603  82488700\n",
       "2024-01-03  183.351746  184.973804  182.535736  183.321893  58414500\n",
       "2024-01-04  181.023178  182.197418  179.998201  181.261998  71983600\n",
       "2024-01-05  180.296707  181.869006  179.291637  181.102771  62303300\n",
       "2024-01-08  184.655365  184.695178  180.615161  181.202281  59144500\n",
       "2024-01-09  184.237411  184.247357  181.839157  183.023358  42841800\n",
       "2024-01-10  185.282303  185.491271  183.023365  183.451277  46792900\n",
       "2024-01-11  184.685226  186.138115  182.724829  185.630592  49128400\n",
       "2024-01-12  185.013611  185.829621  184.287174  185.152928  40444700\n",
       "2024-01-16  182.734772  183.361690  180.047923  181.271937  65603000\n",
       "2024-01-17  181.789383  182.038164  179.420996  180.386269  47317400\n",
       "2024-01-18  187.710419  188.217927  184.924066  185.182793  78005800\n",
       "2024-01-19  190.626114  191.014212  187.899482  188.406990  68741000\n",
       "2024-01-22  192.944748  194.377730  191.322690  191.362503  60133900\n",
       "2024-01-23  194.228470  194.795698  192.885060  194.069261  42355600\n",
       "2024-01-24  193.551773  195.422613  193.392549  194.467286  53631300\n",
       "2024-01-25  193.223404  195.313172  192.168574  194.268288  54822100\n",
       "2024-01-26  191.481918  193.810507  191.004263  193.322905  44594000\n",
       "2024-01-29  190.795288  191.262998  188.655776  191.073922  47145600\n",
       "2024-01-30  187.123260  190.864939  186.556047  190.009132  55859400"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".finenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
